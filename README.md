# Сервис оповещения миллиона пользователей с помощью Tarantool

На написание данной статьи меня натолкнула
[эта статья](https://habrahabr.ru/company/tensor/blog/341068/">статья).

Очень много людей в IT-мире занимается одним и тем же. Расскажу о своём опыте
в решении этих же проблем.

Несколько лет назад мы копали ровно ту же задачу: пользователь хочет в
вебприложении в реальном времени (с задержками, определяемыми только сетью)
получать уведомления о тех или иных событиях.

Если рассмотреть требования в указанной статье:

* на странице "слушаем" в среднем 10 событий
* миллион пользователей
* требуется персистентность (терять события мы не хотим)

Допустим пользователи и являются источником этих событий.
Сделаем несколько допущений/прикидок.

Допустим это некий чат, где весь миллион пользователей что-то постоянно пишет.
Сделаем допущение, что один пользователь генерирует одно сообщение за 10 секунд.

Тогда получим на миллион пользователей генерирует 100 тыс сообщений в секунду.

И тут появляется первый важный аспект что передаем?

## События или данные?

Это традиционная дилемма всех очередей, аггрегаторов, серверов событий:
что является единицей хранения? Поэтому введем понятия:

* **Событие** - это **по возможности минимальная** информационная структура,
хранящая в себе информацию **о факте** события.

С событием могут быть связаны данные:

* **Данные** - это полный набор данных, в том числе слабо связанных с событием.

Например: пользователь `345` оформил заказ на перевозку груза `X`
из точки `А`, в точку `Б`, при оформлении использована банковская
карта `Z` итп.

Информация о том кто (источник события) что сделал (тип, факт события) - это
будем называть событием, а информацию откуда транспортируется груз, какой груз
итп - будем называть данными.

То есть событие - это структура, описывающая в себе факт события,
а данные это все остальное.

Линия разделения событие-данные условная, но все же.

Пример события:

```json
{
    "type": "order",
    "user": 345,
    "status": "created",
    "orderid": 12345
}
```

Пользователь `345` создал заказ `12345`. Заказ на момент отправки события
имел статус `created` (это уже избыточные данные).

Теперь сформирую некое **эмпирическое** правило правильного архитектурного
выбора:

> При разработке очередей, аггегаторов, серверов событий сервера должны
> манипулировать именно событиями, а не данными.

Однако еще раз повторюсь: линия разделения условная: событие из примера содержит
часть данных (поле `status`).

Итак вернемся к задаче: мы строим именно **сервер событий**, поэтому можем
прикинуть трафик. Возьмем например, что среднее событие будет представлять
из себя JSON-хеш о 4-10 элементах, то есть текст размером 60-160 байт.

То есть поток событий обеспечивающий работу миллиона пользователей
(100 тыс событий в секунду) по средним прикидкам будет составлять от 6 до 160
мегабайт в секунду.

Для того чтобы прокачать этот трафик через один узел сети достаточно
(округляя до целых) одного гигабита сети.

Таким образом, по грубым прикидкам для того чтобы персистентно сохранить
поток событий от миллиона пользователей - достаточно ресурсов одного
современного сервера.

Теперь прикинем сколько ресурсов надо на то чтобы доставить эти события
миллиону пользователей.

У каждого конечно своя архитектура, но можно говорить о некоторых общих
принципах.

Скорее всего если одно сообщение надо доставить миллиону пользователей,
то это ошибка в архитектуре (хотя и такое бывает). Нам же надо задаться
какой-то средней величиной. Будем считать что одно событие доставляется
**в среднем** десяти пользователям: в чате у вас в друзьях редко будет
более 10 друзей онлайн, если говорить об исполнении заказов - редко
будет более 10 исполнителей итп.

Таким образом чтобы доставить события в нашей задаче до пользователей,
нужно где-то 10 гигабит трафика.

Таким образом, **теоретически** данную задачу можно решить в рамках
**одного** современного сервера с диском, способным записывать
1гигабит/в сек и сетью способной принять входящий трафик - 1Гбит/сек
и исходящий трафик 10Гбит/сек. Если этот сервер будет кешировать 100%
событий в RAM за последние 10 минут, то RAM ему требуется около 100 гигабайт.

Убедившись что теоретически данную систему можно строить на одном сервере,
попытаемся построить реальную систему.

Начнем с того же вопроса: сохранение данных на диске.

Один из самых быстрых способов хранения закешированных данных на диске - WAL
лог: данные поступают в RAM кеш и дописываются в WAL-лог.
Поскольку данные в WAL-лог только пишутся, пишутся в режиме `append`, то таким
способом можно утилизировать практически 100% пропускной способности записи
диска. Опущу тут рассмотрение недостатков WAL, упомяну лишь то что WAL-логи
очень хорошо приспособлены к репликации



